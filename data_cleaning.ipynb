{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"toc_visible":true,"collapsed_sections":["8iBYrs2QCPsO"],"authorship_tag":"ABX9TyMVsxqIoeooRmF/zSSE/Amv"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"HJipH34x8P-B"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import re   #for additional splitting methods. Used to remove the numbering on cities names\n","from simpledbf import Dbf5    #used to extract cities' positions from a dbf table at https://www.ibge.gov.br/geociencias/organizacao-do-territorio/estrutura-territorial/27385-localidades.html?=&t=acesso-ao-produto\n","import os\n","import glob\n","\n","import matplotlib.pyplot as plt\n","import itertools"]},{"cell_type":"markdown","source":["# --- Dengue, Zika, Influenza ---"],"metadata":{"id":"h4scBcbZGUPC"}},{"cell_type":"code","source":["#Configs\n","disease = 'zika'\n","#path = 'C:/Users/your_path/' + disease + '/'\n","path = 'E:/Doutorado/Trabalhos/Projeto-dengue/data/' + disease + '/raw/'\n","year = 2018"],"metadata":{"id":"ZQ4yZtyb8ckC"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Data for each city"],"metadata":{"id":"vl1ao5W8BMHz"}},{"cell_type":"markdown","source":["###If using dengue of zika data:"],"metadata":{"id":"vyh2AdFkCM6n"}},{"cell_type":"code","source":["lines_to_skip = [0,1,2] + list(range(1143, 5000, 1))   #change according to the file provided in \"[Dengue/Zika] Line skips\" below"],"metadata":{"id":"gnMEOgWeCkMf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df = pd.read_csv(str(path + 'SINAN_zika_' + str(year) + '.csv'), sep=';', encoding='latin1', skiprows=lines_to_skip)\n","\n","# === Uncomment the lines below as needed ===\n","# --- Dengue ---\n","#df.drop(columns=['Em Branco/ign', 'Total', 'Semana 53'], inplace=True)   #2014\n","#df.drop(columns=['Em Branco/ign', 'Total'], inplace=True)   #2015, 2021, 2020\n","#df.drop(columns=['Total'], inplace=True)   #2022, 2019, 2018, 2017, 2016\n","\n","# --- Zika ---\n","#df.drop(columns=['Em Branco/ign', 'Total', 'Semana 53'], inplace=True)   #2014\n","#df.drop(columns=['Em Branco/ign', 'Total'], inplace=True)   #2015, 2021, 2020\n","df.drop(columns=['Total'], inplace=True)   #2022, 2019, 2018, 2017, 2016"],"metadata":{"id":"UH1gp1Q9CwYd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Reworking city names to move the unique codes to another column.\n","\n","renamed = []\n","city_codes = []\n","names = list(df['Município de notificação'])\n","\n","for city in range(0, len(names), 1):\n","  swp = re.split('(\\d+)', names[city])  #split city name in '', number and name\n","  city_codes.append( int(swp[1].strip()) ) #save each city code for later use.\n","  renamed.append(swp[2].strip()) #remove whitespace before the name of a city and save result\n","\n","#Drop the original column and replaces it with the above list\n","n = df.columns[0]   #index of the city list\n","df.drop(n, axis = 1, inplace = True)\n","df[n] = renamed\n","df['cod_city'] = city_codes"],"metadata":{"id":"D16oCXnPeFqz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Reorganize the placement of the new name list and show the resulting dataframe\n","#-> The code is duplicated to move both the city names and codes to the beginning of the dataframe.\n","cols = df.columns.tolist()\n","cols = cols[-1:] + cols[:-1]\n","df = df[cols]\n","df\n","\n","cols = df.columns.tolist()\n","cols = cols[-1:] + cols[:-1]\n","df = df[cols]\n","df\n","\n","#replace values listed as \"-\" with NaN, excluding the cities column (some have \"-\" in their names)\n","for col in df.columns:\n","  if col != 'Município de notificação':\n","    df[col].replace({'-': np.NaN}, regex=True, inplace=True)"],"metadata":{"id":"ZtJYkF4Ga2PL"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### If using influenza data:"],"metadata":{"id":"8iBYrs2QCPsO"}},{"cell_type":"markdown","source":["Original download from https://opendatasus.saude.gov.br/dataset/srag-2013-2018"],"metadata":{"id":"vCQOqBnC98Uo"}},{"cell_type":"code","source":["df = pd.read_csv(str(path + disease + str(year) + '.csv'), delimiter=';', encoding='latin')"],"metadata":{"id":"4LKpb_c-8t78","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1711998348432,"user_tz":0,"elapsed":267,"user":{"displayName":"Luiza Lober de Souza Piva","userId":"13136650427747089256"}},"outputId":"3ca7bdf6-c1e7-4c58-f762-1a6371931f3c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["C:\\Users\\Luiza\\AppData\\Local\\Temp\\ipykernel_12132\\576409684.py:1: DtypeWarning: Columns (74) have mixed types. Specify dtype option on import or set low_memory=False.\n","  df = pd.read_csv(str(path + disease + str(year) + '.csv'), delimiter=';', encoding='latin')\n"]}]},{"cell_type":"code","source":["df.DT_NOTIFIC = pd.to_datetime(df.DT_NOTIFIC, format=\"%d/%m/%Y\")\n","df['Year'] = df['DT_NOTIFIC'].apply(lambda time: time.year)\n","df['Week'] = df['DT_NOTIFIC'].apply(lambda time: time.week)\n","\n","df.sort_values(by=['Week', 'ID_MUNICIP'], inplace=True)\n","#somehow there is more than one year in this dataframe\n","df.drop(columns='NU_ANO', inplace=True)\n","df = df.loc[df['Year'] == int(year)]\n","\n","df.CS_SEXO[df.CS_SEXO == 'M'] = 1\n","df.CS_SEXO[df.CS_SEXO == 'F'] = 1\n","df.CS_SEXO[df.CS_SEXO == 'I'] = 1\n","df['CONTAGEM'] = df.groupby(by=['Week', 'ID_MUNICIP'])['CS_SEXO'].transform('sum')\n","\n","df.sort_values(by=['DT_NOTIFIC'], inplace=True)\n","df = df[['DT_NOTIFIC', 'ID_MUNICIP', 'Year', 'Week', 'CONTAGEM']]"],"metadata":{"id":"Qt2FUbAByFtj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":424},"id":"uJ7a5v6BC40g","executionInfo":{"status":"ok","timestamp":1711998353365,"user_tz":0,"elapsed":17,"user":{"displayName":"Luiza Lober de Souza Piva","userId":"13136650427747089256"}},"outputId":"872e7827-b1e5-47a1-d3d2-846b3e02bd04"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["      DT_NOTIFIC  ID_MUNICIP  Year  Week CONTAGEM\n","25394 2018-01-01      355030  2018     1        7\n","33623 2018-01-01      410830  2018     1        6\n","36610 2018-01-01      410830  2018     1        6\n","30500 2018-01-02      355630  2018     1        1\n","13747 2018-01-02      320530  2018     1        1\n","...          ...         ...   ...   ...      ...\n","38176 2018-12-31      420540  2018     1        2\n","42823 2018-12-31      431680  2018     1        1\n","44132 2018-12-31      500270  2018     1        5\n","29038 2018-12-31      355030  2018     1        7\n","33475 2018-12-31      410690  2018     1        7\n","\n","[47539 rows x 5 columns]"],"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>DT_NOTIFIC</th>\n","      <th>ID_MUNICIP</th>\n","      <th>Year</th>\n","      <th>Week</th>\n","      <th>CONTAGEM</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>25394</th>\n","      <td>2018-01-01</td>\n","      <td>355030</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>33623</th>\n","      <td>2018-01-01</td>\n","      <td>410830</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>36610</th>\n","      <td>2018-01-01</td>\n","      <td>410830</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>6</td>\n","    </tr>\n","    <tr>\n","      <th>30500</th>\n","      <td>2018-01-02</td>\n","      <td>355630</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>13747</th>\n","      <td>2018-01-02</td>\n","      <td>320530</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>38176</th>\n","      <td>2018-12-31</td>\n","      <td>420540</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>42823</th>\n","      <td>2018-12-31</td>\n","      <td>431680</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>44132</th>\n","      <td>2018-12-31</td>\n","      <td>500270</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>29038</th>\n","      <td>2018-12-31</td>\n","      <td>355030</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>7</td>\n","    </tr>\n","    <tr>\n","      <th>33475</th>\n","      <td>2018-12-31</td>\n","      <td>410690</td>\n","      <td>2018</td>\n","      <td>1</td>\n","      <td>7</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>47539 rows × 5 columns</p>\n","</div>"]},"metadata":{},"execution_count":70}]},{"cell_type":"markdown","source":["## Adding geographic distances"],"metadata":{"id":"8xBW3t0dpvhb"}},{"cell_type":"markdown","source":["**Important**: Sadly you can't mix the city codes from the IBGE dataset and those from SINAN's. The former have numberings with seven digits (while the latter has six) that do not overlap with latter.\n","\n","Proof:\n","\n","\n","\n","```\n","test = []\n","\n","for number in list(df_loc['MUN_ORIGEM'].unique()):\n","  operationTwo = number\n","  test.append( operationTwo // 10 )\n","\n","len(set(test) & set(df['cod_city'].unique())) #3710 vs 3774\n","```\n","\n"],"metadata":{"id":"XXA-6q0isjhn"}},{"cell_type":"code","source":["path = 'C:/Users/your_path/'\n","path = 'E:/Doutorado/Trabalhos/Projeto-dengue/data/IBGE/'\n","dbf = Dbf5(path + 'BR_Localidades_2010_v1.dbf', codec='latin')\n","df_loc = dbf.to_dataframe()"],"metadata":{"id":"FpcCOnU6p0Sk"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Dictionaty to convert full lenght UF names to codes\n","#-> for some reason, the original dataframe, df, does not have data for Espirito Santo\n","uf_code = ['RO', 'AC', 'AM', 'RR', 'PA', 'AP', 'TO', 'MA', 'PI', 'CE', 'RN',\n","       'PB', 'PE', 'AL', 'SE', 'BA', 'MG', 'ES', 'RJ', 'SP', 'PR', 'SC', 'RS',\n","       'MS', 'MT', 'GO', 'DF']\n","uf_names = list(df_loc['NM_UF'].unique())\n","\n","for i in range(len(uf_code)):\n","    df_loc['NM_UF'] = df_loc['NM_UF'].replace(uf_names[i],uf_code[i])"],"metadata":{"id":"wW1Ye2FP3mOi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#-> Removing accents\n","cols = df_loc.select_dtypes(include=[object]).columns\n","df_loc[cols] = df_loc[cols].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))"],"metadata":{"id":"hsF5t0hEuWk5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["df_loc = df_loc.loc[df_loc['NM_CATEGOR'] == 'CIDADE']\n","df_loc['ID_MUNICIP'] = pd.to_numeric(df_loc['CD_GEOCODM'].str[:-1])\n","\n","df_loc.sort_values(by=['ID_MUNICIP'], inplace=True)"],"metadata":{"id":"sj8BZbdW620K"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run for Influenza"],"metadata":{"id":"3UYF-nSQE2EG"}},{"cell_type":"code","source":["x_coord = []\n","y_coord = []\n","city_to_remove = []\n","\n","for city in list(df['ID_MUNICIP'].unique()):\n","  df_city = df_loc.loc[df_loc['ID_MUNICIP'] == city]\n","  size_city_data = len(df.loc[df['ID_MUNICIP'] == city])\n","  if (len(df_city) != 0):\n","    x = df_city['LAT'].values[0]\n","    y = df_city['LONG'].values[0]\n","    x_coord.append( np.repeat(x, size_city_data) )\n","    y_coord.append( np.repeat(y, size_city_data) )\n","  else:\n","    city_to_remove.append(city)\n","\n","x_coord = list(itertools.chain(*x_coord))\n","y_coord = list(itertools.chain(*y_coord))\n","\n","for city in city_to_remove:\n","  df = df[df['ID_MUNICIP'] != city]\n","\n","\n","#Add the positions found\n","df['x_coord'] = x_coord\n","df['y_coord'] = y_coord\n","\n","df = df[['ID_MUNICIP', 'Week', 'x_coord', 'y_coord', 'CONTAGEM']]"],"metadata":{"id":"sp2QtpjJtNDF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#expand the dataframe. Is there a better way to do that?\n","weeks_full_year = list(range(1,53))\n","\n","swp_id = []\n","swp_xcoord = []\n","swp_ycoord = []\n","swp_contagem = []\n","\n","for city in df['ID_MUNICIP'].unique():\n","  cont = 0\n","  list_weeks = df.loc[df['ID_MUNICIP'] == city]['Week'].values\n","  weeks_cases = df.loc[df['ID_MUNICIP'] == city]['CONTAGEM'].values\n","\n","  swp_id.append( np.repeat(city, len(weeks_full_year)) )\n","  swp_xcoord.append( np.repeat(df.loc[df['ID_MUNICIP'] == city]['x_coord'].values[0], len(weeks_full_year)) )\n","  swp_ycoord.append( np.repeat(df.loc[df['ID_MUNICIP'] == city]['y_coord'].values[0], len(weeks_full_year)) )\n","\n","  for value in weeks_full_year:\n","    if value in list_weeks:\n","      swp_contagem.append( weeks_cases[cont] )\n","      cont = cont+1\n","    else:\n","      swp_contagem.append(0)\n","\n","swp_year = np.repeat(int('20' + str(year)), len(swp_contagem))\n","swp_id = list(itertools.chain(*swp_id))\n","swp_xcoord = list(itertools.chain(*swp_xcoord))\n","swp_ycoord = list(itertools.chain(*swp_ycoord))"],"metadata":{"id":"L78OAfXgJIP7"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data = {'Year': swp_year, 'cod_city':swp_id, 'week': np.tile(weeks_full_year, len(df['ID_MUNICIP'].unique())),\n","        'x_coord': swp_xcoord, 'y_coord': swp_ycoord, 'cases':swp_contagem}\n","\n","df_final = pd.DataFrame(data)"],"metadata":{"id":"Q2i6NPoTNSZm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Run for Dengue/Zika"],"metadata":{"id":"kN3UluUQE5G5"}},{"cell_type":"code","source":["x_coord = []\n","y_coord = []\n","city_to_remove = []\n","\n","for city in list(df['cod_city'].unique()):\n","  df_city = df_loc.loc[df_loc['ID_MUNICIP'] == city]\n","  size_city_data = len(df.loc[df['cod_city'] == city])\n","  if (len(df_city) != 0):\n","    x = df_city['LAT'].values[0]\n","    y = df_city['LONG'].values[0]\n","    x_coord.append( np.repeat(x, size_city_data) )\n","    y_coord.append( np.repeat(y, size_city_data) )\n","  else:\n","    city_to_remove.append(city)\n","\n","x_coord = list(itertools.chain(*x_coord))\n","y_coord = list(itertools.chain(*y_coord))"],"metadata":{"id":"T4XXEbnkE64L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for city in city_to_remove:\n","  df = df[df['cod_city'] != city]"],"metadata":{"id":"58aOEQXoEQp5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#rename weeks to a easier to access format.\n","#-> The other variables (and those from the INMET dataframes) will be translated in another notebook.\n","cols = list(df.select_dtypes(include=[object]).columns)[1:]\n","\n","for week in range(0, len(cols), 1):\n","  df.rename(columns={cols[week]: str('w_'+str(week+1))}, inplace=True)"],"metadata":{"id":"QHd3Mva-Cxsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Add the positions found in the previous cell\n","df['x_coord'] = x_coord\n","df['y_coord'] = y_coord\n","\n","df = df[['cod_city', 'x_coord', 'y_coord', 'w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6',\n","       'w_7', 'w_8', 'w_9', 'w_10', 'w_11', 'w_12', 'w_13', 'w_14', 'w_15',\n","       'w_16', 'w_17', 'w_18', 'w_19', 'w_20', 'w_21', 'w_22', 'w_23', 'w_24',\n","       'w_25', 'w_26', 'w_27', 'w_28', 'w_29', 'w_30', 'w_31', 'w_32', 'w_33',\n","       'w_34', 'w_35', 'w_36', 'w_37', 'w_38', 'w_39', 'w_40', 'w_41', 'w_42',\n","       'w_43', 'w_44', 'w_45', 'w_46', 'w_47', 'w_48', 'w_49', 'w_50', 'w_51',\n","       'w_52']]"],"metadata":{"id":"2AlXSCdj8igX"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Saving results"],"metadata":{"id":"utKZY7IFYJLU"}},{"cell_type":"code","source":["#Done! Let's save the resulting data.\n","df.to_csv(str(path + '/SINAN_' + disease + 'weekly_' + str(year) + '.csv'))"],"metadata":{"id":"jXT4TzaXOHvZ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["##[Dengue/Zika] Line skips"],"metadata":{"id":"ohCOVCwKFt53"}},{"cell_type":"markdown","source":["### Dengue"],"metadata":{"id":"Be5cpWfaFxRP"}},{"cell_type":"code","source":["#2007:\n","lines_to_skip = [0,1,2] + list(range(3559, 5000, 1))\n","\n","#2008:\n","lines_to_skip = [0,1,2] + list(range(3363, 5000, 1))\n","\n","#2009:\n","lines_to_skip = [0,1,2] + list(range(3041, 5000, 1))\n","\n","#2010:\n","lines_to_skip = [0,1,2] + list(range(3939, 5000, 1))\n","\n","#2011:\n","lines_to_skip = [0,1,2] + list(range(3841, 5000, 1))\n","\n","#2012:\n","lines_to_skip = [0,1,2] + list(range(3567, 5000, 1))\n","\n","#2013:\n","lines_to_skip = [0,1,2] + list(range(4221, 5000, 1))\n","\n","#2014:\n","lines_to_skip = [0,1,2] + list(range(3694, 5000, 1))\n","\n","#2015:\n","lines_to_skip = [0,1,2] + list(range(4365, 5000, 1))\n","\n","#2016:\n","lines_to_skip = [0,1,2] + list(range(4550, 5000, 1))\n","\n","#2017:\n","lines_to_skip = [0,1,2] + list(range(3268, 5000, 1))\n","\n","#2018:\n","lines_to_skip = [0,1,2] + list(range(3168, 5000, 1))\n","\n","#2019:\n","lines_to_skip = [0,1,2] + list(range(4339, 5000, 1))\n","\n","#2020:\n","lines_to_skip = [0,1,2] + list(range(4080, 5000, 1))\n","\n","#2021:\n","lines_to_skip = [0,1,2] + list(range(3778, 5000, 1))"],"metadata":{"id":"b64cXzLOG5Nw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Zika"],"metadata":{"id":"swCiBel9FykD"}},{"cell_type":"code","source":["#2016:\n","lines_to_skip = [0,1,2] + list(range(2375, 5000, 1))\n","\n","#2017:\n","lines_to_skip = [0,1,2] + list(range(1258, 5000, 1))\n","\n","#2018:\n","lines_to_skip = [0,1,2] + list(range(1143, 5000, 1))\n","\n","#2019:\n","lines_to_skip = [0,1,2] + list(range(1463, 5000, 1))\n","\n","#2020:\n","lines_to_skip = [0,1,2] + list(range(1094, 5000, 1))\n","\n","#2021:\n","lines_to_skip = [0,1,2] + list(range(941, 5000, 1))\n","\n","#2022:\n","lines_to_skip = [0,1,2] + list(range(1159, 5000, 1))\n","\n","#2023:\n","lines_to_skip = [0,1,2] + list(range(1057, 5000, 1))"],"metadata":{"id":"tWdJs35b73tv"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# --- COVID19 ----"],"metadata":{"id":"vXRfKnWMGHLF"}},{"cell_type":"code","source":["path = \"C:/Users/your_path/\"\n","file_list = [os.path.normpath(i) for i in glob.glob(path + \"/*.csv\")]\n","main_dataframe = pd.read_csv(file_list[0], delimiter=';')\n","for i in range(1,len(file_list)):\n","    df = pd.read_csv(file_list[i], delimiter=';')\n","    main_dataframe = pd.concat([main_dataframe,df],axis=0)"],"metadata":{"id":"iOWh6CJyRP3X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["main_dataframe.columns"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Y5LogUozUNgV","executionInfo":{"status":"ok","timestamp":1711996761917,"user_tz":0,"elapsed":17,"user":{"displayName":"Luiza Lober de Souza Piva","userId":"13136650427747089256"}},"outputId":"40f1d10e-54b7-44dc-9164-f741c33ccff2"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Index(['regiao', 'estado', 'municipio', 'coduf', 'codmun', 'codRegiaoSaude',\n","       'nomeRegiaoSaude', 'data', 'semanaEpi', 'populacaoTCU2019',\n","       'casosAcumulado', 'casosNovos', 'obitosAcumulado', 'obitosNovos',\n","       'Recuperadosnovos', 'emAcompanhamentoNovos', 'interior/metropolitana'],\n","      dtype='object')"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["main_dataframe = main_dataframe[['estado', 'municipio', 'codmun', 'data',\n","                                 'semanaEpi','casosAcumulado', 'casosNovos']]\n","main_dataframe.dropna(subset=['estado','municipio', 'codmun'], inplace=True)\n","\n","main_dataframe.set_index('data', inplace=True)\n","main_dataframe.index = pd.to_datetime(main_dataframe.index)"],"metadata":{"id":"vOPLRK6UTYzF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_to_concatenate = []\n","for column in main_dataframe.columns[4:]:\n","  grouped = main_dataframe.groupby('codmun').resample('1W')[column].sum()\n","  data_to_concatenate.append(grouped.to_frame())\n","\n","res = pd.concat(data_to_concatenate, axis=1)\n","\n","res = res.reset_index(level=[0,1])\n","res['year'] = pd.DatetimeIndex(res['data']).year\n","res['week'] = res['data'].dt.strftime(\"%U\")\n","res['week'] = pd.to_numeric(res['week'])"],"metadata":{"id":"lK6jDAa9YD3l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["res.rename(columns={'codmun': 'cod_city'})\n","res = res[['cod_city', 'year', 'week', 'data', 'casosAcumulado', 'casosNovos']]\n","res['casosNovos'].mask(res['casosNovos'] <0 , 0, inplace=True)  #remove negative values. There seems to be a bug in the original data which needs to be fixed.\n","\n","res.to_csv(path + 'covid_2020_2023.csv')"],"metadata":{"id":"JJ1N880JdC5s"},"execution_count":null,"outputs":[]}]}