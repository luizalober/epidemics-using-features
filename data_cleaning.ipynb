{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "collapsed_sections": [
        "8iBYrs2QCPsO"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJipH34x8P-B"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re   #for additional splitting methods. Used to remove the numbering on cities names\n",
        "from simpledbf import Dbf5    #used to extract cities' positions from a dbf table at https://www.ibge.gov.br/geociencias/organizacao-do-territorio/estrutura-territorial/27385-localidades.html?=&t=acesso-ao-produto\n",
        "import os\n",
        "import glob\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- Dengue, Zika, Influenza ---"
      ],
      "metadata": {
        "id": "h4scBcbZGUPC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Configs\n",
        "disease = 'dengue'\n",
        "path = 'your_path/' + disease + '/'\n",
        "year = 2018"
      ],
      "metadata": {
        "id": "ZQ4yZtyb8ckC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data for each city"
      ],
      "metadata": {
        "id": "vl1ao5W8BMHz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###If using dengue of zika data:"
      ],
      "metadata": {
        "id": "vyh2AdFkCM6n"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lines_to_skip = [0,1,2] + list(range(3168, 5000, 1))  #change according to the file provided in \"[Dengue/Zika] Line skips\" below"
      ],
      "metadata": {
        "id": "gnMEOgWeCkMf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(str(path + 'filename' + '.csv'), sep=';', encoding='latin1', skiprows=lines_to_skip)\n",
        "\n",
        "# === Uncomment the lines below as needed ===\n",
        "# --- Dengue ---\n",
        "#df.drop(columns=['Em Branco/ign', 'Total', 'Semana 53'], inplace=True)   #2014\n",
        "#df.drop(columns=['Em Branco/ign', 'Total'], inplace=True)   #2015, 2020, 2021\n",
        "df.drop(columns=['Total'], inplace=True)   #2019, 2017, 2016, 2018, 2019, 2022\n",
        "\n",
        "# --- Zika ---\n",
        "#df.drop(columns=['Em Branco/ign', 'Total', 'Semana 53'], inplace=True)   #2014\n",
        "#df.drop(columns=['Em Branco/ign', 'Total'], inplace=True)   #2015, 2020, 2021\n",
        "#df.drop(columns=['Total'], inplace=True)   #2016, 2017, 2018, 2019, 2022"
      ],
      "metadata": {
        "id": "UH1gp1Q9CwYd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reworking city names to move the unique codes to another column.\n",
        "\n",
        "renamed = []\n",
        "city_codes = []\n",
        "names = list(df['Município de notificação'])\n",
        "\n",
        "for city in range(0, len(names), 1):\n",
        "  swp = re.split('(\\d+)', names[city])  #split city name in '', number and name\n",
        "  city_codes.append( int(swp[1].strip()) ) #save each city code for later use.\n",
        "  renamed.append(swp[2].strip()) #remove whitespace before the name of a city and save result\n",
        "\n",
        "#Drop the original column and replaces it with the above list\n",
        "n = df.columns[0]   #index of the city list\n",
        "df.drop(n, axis = 1, inplace = True)\n",
        "df[n] = renamed\n",
        "df['cod_city'] = city_codes"
      ],
      "metadata": {
        "id": "D16oCXnPeFqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reorganize the placement of the new name list and show the resulting dataframe\n",
        "#-> The code is duplicated to move both the city names and codes to the beginning of the dataframe.\n",
        "cols = df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df = df[cols]\n",
        "df\n",
        "\n",
        "cols = df.columns.tolist()\n",
        "cols = cols[-1:] + cols[:-1]\n",
        "df = df[cols]\n",
        "df\n",
        "\n",
        "#replace values listed as \"-\" with NaN, excluding the cities column (some have \"-\" in their names)\n",
        "for col in df.columns:\n",
        "  if col != 'Município de notificação':\n",
        "    df[col].replace({'-': np.NaN}, regex=True, inplace=True)"
      ],
      "metadata": {
        "id": "ZtJYkF4Ga2PL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### If using influenza data:"
      ],
      "metadata": {
        "id": "8iBYrs2QCPsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Original download from https://opendatasus.saude.gov.br/dataset/srag-2013-2018"
      ],
      "metadata": {
        "id": "vCQOqBnC98Uo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(str(path + disease + str(year) + '.csv'), delimiter=';', encoding='latin')"
      ],
      "metadata": {
        "id": "4LKpb_c-8t78"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.DT_NOTIFIC = pd.to_datetime(df.DT_NOTIFIC, format=\"%d/%m/%Y\")\n",
        "df['Year'] = df['DT_NOTIFIC'].apply(lambda time: time.year)\n",
        "df['Week'] = df['DT_NOTIFIC'].apply(lambda time: time.week)\n",
        "\n",
        "df.sort_values(by=['Week', 'ID_MUNICIP'], inplace=True)\n",
        "#somehow there is more than one year in this dataframe\n",
        "df.drop(columns='NU_ANO', inplace=True)\n",
        "df = df.loc[df['Year'] == int(year)]\n",
        "\n",
        "df.CS_SEXO[df.CS_SEXO == 'M'] = 1\n",
        "df.CS_SEXO[df.CS_SEXO == 'F'] = 1\n",
        "df.CS_SEXO[df.CS_SEXO == 'I'] = 1\n",
        "df['CONTAGEM'] = df.groupby(by=['Week', 'ID_MUNICIP'])['CS_SEXO'].transform('sum')\n",
        "\n",
        "df.sort_values(by=['DT_NOTIFIC'], inplace=True)\n",
        "df = df[['DT_NOTIFIC', 'ID_MUNICIP', 'Year', 'Week', 'CONTAGEM']]"
      ],
      "metadata": {
        "id": "Qt2FUbAByFtj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding geographic distances"
      ],
      "metadata": {
        "id": "8xBW3t0dpvhb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: Sadly you can't mix the city codes from the IBGE dataset and those from SINAN's. The former have numberings with seven digits (while the latter has six) that do not overlap with latter.\n",
        "\n",
        "Proof:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "test = []\n",
        "\n",
        "for number in list(df_loc['MUN_ORIGEM'].unique()):\n",
        "  operationTwo = number\n",
        "  test.append( operationTwo // 10 )\n",
        "\n",
        "len(set(test) & set(df['cod_city'].unique())) #3710 vs 3774\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "XXA-6q0isjhn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'your_path/'\n",
        "dbf = Dbf5(path + 'BR_Localidades_2010_v1.dbf', codec='latin')\n",
        "df_loc = dbf.to_dataframe()"
      ],
      "metadata": {
        "id": "FpcCOnU6p0Sk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionaty to convert full lenght UF names to codes\n",
        "#-> for some reason, the original dataframe, df, does not have data for Espirito Santo\n",
        "uf_code = ['RO', 'AC', 'AM', 'RR', 'PA', 'AP', 'TO', 'MA', 'PI', 'CE', 'RN',\n",
        "       'PB', 'PE', 'AL', 'SE', 'BA', 'MG', 'ES', 'RJ', 'SP', 'PR', 'SC', 'RS',\n",
        "       'MS', 'MT', 'GO', 'DF']\n",
        "uf_names = list(df_loc['NM_UF'].unique())\n",
        "\n",
        "for i in range(len(uf_code)):\n",
        "    df_loc['NM_UF'] = df_loc['NM_UF'].replace(uf_names[i],uf_code[i])"
      ],
      "metadata": {
        "id": "wW1Ye2FP3mOi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-> Removing accents\n",
        "cols = df_loc.select_dtypes(include=[object]).columns\n",
        "df_loc[cols] = df_loc[cols].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))"
      ],
      "metadata": {
        "id": "hsF5t0hEuWk5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loc = df_loc.loc[df_loc['NM_CATEGOR'] == 'CIDADE']\n",
        "df_loc['ID_MUNICIP'] = pd.to_numeric(df_loc['CD_GEOCODM'].str[:-1])\n",
        "\n",
        "df_loc.sort_values(by=['ID_MUNICIP'], inplace=True)"
      ],
      "metadata": {
        "id": "sj8BZbdW620K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run for Influenza"
      ],
      "metadata": {
        "id": "3UYF-nSQE2EG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_coord = []\n",
        "y_coord = []\n",
        "city_to_remove = []\n",
        "\n",
        "for city in list(df['ID_MUNICIP'].unique()):\n",
        "  df_city = df_loc.loc[df_loc['ID_MUNICIP'] == city]\n",
        "  size_city_data = len(df.loc[df['ID_MUNICIP'] == city])\n",
        "  if (len(df_city) != 0):\n",
        "    x = df_city['LAT'].values[0]\n",
        "    y = df_city['LONG'].values[0]\n",
        "    x_coord.append( np.repeat(x, size_city_data) )\n",
        "    y_coord.append( np.repeat(y, size_city_data) )\n",
        "  else:\n",
        "    city_to_remove.append(city)\n",
        "\n",
        "x_coord = list(itertools.chain(*x_coord))\n",
        "y_coord = list(itertools.chain(*y_coord))\n",
        "\n",
        "for city in city_to_remove:\n",
        "  df = df[df['ID_MUNICIP'] != city]\n",
        "\n",
        "\n",
        "#Add the positions found\n",
        "df['x_coord'] = x_coord\n",
        "df['y_coord'] = y_coord\n",
        "\n",
        "df = df[['ID_MUNICIP', 'Week', 'x_coord', 'y_coord', 'CONTAGEM']]"
      ],
      "metadata": {
        "id": "sp2QtpjJtNDF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#expand the dataframe. Is there a better way to do that?\n",
        "weeks_full_year = list(range(1,53))\n",
        "\n",
        "swp_id = []\n",
        "swp_xcoord = []\n",
        "swp_ycoord = []\n",
        "swp_contagem = []\n",
        "\n",
        "for city in df['ID_MUNICIP'].unique():\n",
        "  cont = 0\n",
        "  list_weeks = df.loc[df['ID_MUNICIP'] == city]['Week'].values\n",
        "  weeks_cases = df.loc[df['ID_MUNICIP'] == city]['CONTAGEM'].values\n",
        "\n",
        "  swp_id.append( np.repeat(city, len(weeks_full_year)) )\n",
        "  swp_xcoord.append( np.repeat(df.loc[df['ID_MUNICIP'] == city]['x_coord'].values[0], len(weeks_full_year)) )\n",
        "  swp_ycoord.append( np.repeat(df.loc[df['ID_MUNICIP'] == city]['y_coord'].values[0], len(weeks_full_year)) )\n",
        "\n",
        "  for value in weeks_full_year:\n",
        "    if value in list_weeks:\n",
        "      swp_contagem.append( weeks_cases[cont] )\n",
        "      cont = cont+1\n",
        "    else:\n",
        "      swp_contagem.append(0)\n",
        "\n",
        "swp_year = np.repeat(int('20' + str(year)), len(swp_contagem))\n",
        "swp_id = list(itertools.chain(*swp_id))\n",
        "swp_xcoord = list(itertools.chain(*swp_xcoord))\n",
        "swp_ycoord = list(itertools.chain(*swp_ycoord))"
      ],
      "metadata": {
        "id": "L78OAfXgJIP7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = {'Year': swp_year, 'cod_city':swp_id, 'week': np.tile(weeks_full_year, len(df['ID_MUNICIP'].unique())),\n",
        "        'x_coord': swp_xcoord, 'y_coord': swp_ycoord, 'cases':swp_contagem}\n",
        "\n",
        "df_final = pd.DataFrame(data)"
      ],
      "metadata": {
        "id": "Q2i6NPoTNSZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run for Dengue/Zika"
      ],
      "metadata": {
        "id": "kN3UluUQE5G5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_coord = []\n",
        "y_coord = []\n",
        "city_to_remove = []\n",
        "\n",
        "for city in list(df['cod_city'].unique()):\n",
        "  df_city = df_loc.loc[df_loc['ID_MUNICIP'] == city]\n",
        "  size_city_data = len(df.loc[df['cod_city'] == city])\n",
        "  if (len(df_city) != 0):\n",
        "    x = df_city['LAT'].values[0]\n",
        "    y = df_city['LONG'].values[0]\n",
        "    x_coord.append( np.repeat(x, size_city_data) )\n",
        "    y_coord.append( np.repeat(y, size_city_data) )\n",
        "  else:\n",
        "    city_to_remove.append(city)\n",
        "\n",
        "x_coord = list(itertools.chain(*x_coord))\n",
        "y_coord = list(itertools.chain(*y_coord))"
      ],
      "metadata": {
        "id": "T4XXEbnkE64L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for city in city_to_remove:\n",
        "  df = df[df['cod_city'] != city]"
      ],
      "metadata": {
        "id": "58aOEQXoEQp5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#rename weeks to a easier to access format.\n",
        "#-> The other variables (and those from the INMET dataframes) will be translated in another notebook.\n",
        "cols = list(df.select_dtypes(include=[object]).columns)[1:]\n",
        "\n",
        "for week in range(0, len(cols), 1):\n",
        "  df.rename(columns={cols[week]: str('w_'+str(week+1))}, inplace=True)"
      ],
      "metadata": {
        "id": "QHd3Mva-Cxsc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the positions found in the previous cell\n",
        "df['x_coord'] = x_coord\n",
        "df['y_coord'] = y_coord\n",
        "\n",
        "df = df[['cod_city', 'x_coord', 'y_coord', 'w_1', 'w_2', 'w_3', 'w_4', 'w_5', 'w_6',\n",
        "       'w_7', 'w_8', 'w_9', 'w_10', 'w_11', 'w_12', 'w_13', 'w_14', 'w_15',\n",
        "       'w_16', 'w_17', 'w_18', 'w_19', 'w_20', 'w_21', 'w_22', 'w_23', 'w_24',\n",
        "       'w_25', 'w_26', 'w_27', 'w_28', 'w_29', 'w_30', 'w_31', 'w_32', 'w_33',\n",
        "       'w_34', 'w_35', 'w_36', 'w_37', 'w_38', 'w_39', 'w_40', 'w_41', 'w_42',\n",
        "       'w_43', 'w_44', 'w_45', 'w_46', 'w_47', 'w_48', 'w_49', 'w_50', 'w_51',\n",
        "       'w_52']]"
      ],
      "metadata": {
        "id": "2AlXSCdj8igX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving results"
      ],
      "metadata": {
        "id": "utKZY7IFYJLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Done! Let's save the resulting data.\n",
        "df.to_csv(str(path + '/SINAN_' + disease + 'weekly_' + str(year) + '.csv'))"
      ],
      "metadata": {
        "id": "sDQKcrUWYvaI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##[Dengue/Zika] Line skips"
      ],
      "metadata": {
        "id": "ohCOVCwKFt53"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dengue"
      ],
      "metadata": {
        "id": "Be5cpWfaFxRP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2007:\n",
        "lines_to_skip = [0,1,2] + list(range(3559, 5000, 1))\n",
        "\n",
        "#2008:\n",
        "lines_to_skip = [0,1,2] + list(range(3363, 5000, 1))\n",
        "\n",
        "#2009:\n",
        "lines_to_skip = [0,1,2] + list(range(3041, 5000, 1))\n",
        "\n",
        "#2010:\n",
        "lines_to_skip = [0,1,2] + list(range(3939, 5000, 1))\n",
        "\n",
        "#2011:\n",
        "lines_to_skip = [0,1,2] + list(range(3841, 5000, 1))\n",
        "\n",
        "#2012:\n",
        "lines_to_skip = [0,1,2] + list(range(3567, 5000, 1))\n",
        "\n",
        "#2013:\n",
        "lines_to_skip = [0,1,2] + list(range(4221, 5000, 1))\n",
        "\n",
        "#2014:\n",
        "lines_to_skip = [0,1,2] + list(range(3694, 5000, 1))\n",
        "\n",
        "#2015:\n",
        "lines_to_skip = [0,1,2] + list(range(4365, 5000, 1))\n",
        "\n",
        "#2016:\n",
        "lines_to_skip = [0,1,2] + list(range(4550, 5000, 1))\n",
        "\n",
        "#2017:\n",
        "lines_to_skip = [0,1,2] + list(range(3268, 5000, 1))\n",
        "\n",
        "#2018:\n",
        "lines_to_skip = [0,1,2] + list(range(3168, 5000, 1))\n",
        "\n",
        "#2019:\n",
        "lines_to_skip = [0,1,2] + list(range(4339, 5000, 1))\n",
        "\n",
        "#2020:\n",
        "lines_to_skip = [0,1,2] + list(range(4080, 5000, 1))\n",
        "\n",
        "#2021:\n",
        "lines_to_skip = [0,1,2] + list(range(3778, 5000, 1))"
      ],
      "metadata": {
        "id": "b64cXzLOG5Nw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zika"
      ],
      "metadata": {
        "id": "swCiBel9FykD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#2016:\n",
        "lines_to_skip = [0,1,2] + list(range(2375, 5000, 1))\n",
        "\n",
        "#2017:\n",
        "lines_to_skip = [0,1,2] + list(range(1258, 5000, 1))\n",
        "\n",
        "#2018:\n",
        "lines_to_skip = [0,1,2] + list(range(1143, 5000, 1))\n",
        "\n",
        "#2019:\n",
        "lines_to_skip = [0,1,2] + list(range(1463, 5000, 1))\n",
        "\n",
        "#2020:\n",
        "lines_to_skip = [0,1,2] + list(range(1094, 5000, 1))\n",
        "\n",
        "#2021:\n",
        "lines_to_skip = [0,1,2] + list(range(941, 5000, 1))\n",
        "\n",
        "#2022:\n",
        "lines_to_skip = [0,1,2] + list(range(1159, 5000, 1))\n",
        "\n",
        "#2023:\n",
        "lines_to_skip = [0,1,2] + list(range(1057, 5000, 1))"
      ],
      "metadata": {
        "id": "tWdJs35b73tv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# --- COVID19 ----"
      ],
      "metadata": {
        "id": "vXRfKnWMGHLF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = \"your_path/\"\n",
        "disease = 'covid'\n",
        "file_list = [os.path.normpath(i) for i in glob.glob(path + \"/*.csv\")]\n",
        "main_dataframe = pd.read_csv(file_list[0], delimiter=';')\n",
        "for i in range(1,len(file_list)):\n",
        "    df = pd.read_csv(file_list[i], delimiter=';')\n",
        "    main_dataframe = pd.concat([main_dataframe,df],axis=0)"
      ],
      "metadata": {
        "id": "iOWh6CJyRP3X"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_dataframe.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5LogUozUNgV",
        "outputId": "990e9767-43cd-4cb6-85f9-1a5f3f91010d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['regiao', 'estado', 'municipio', 'coduf', 'codmun', 'codRegiaoSaude',\n",
              "       'nomeRegiaoSaude', 'data', 'semanaEpi', 'populacaoTCU2019',\n",
              "       'casosAcumulado', 'casosNovos', 'obitosAcumulado', 'obitosNovos',\n",
              "       'Recuperadosnovos', 'emAcompanhamentoNovos', 'interior/metropolitana'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "main_dataframe = main_dataframe[['estado', 'municipio', 'codmun', 'data',\n",
        "                                 'semanaEpi','casosAcumulado', 'casosNovos']]\n",
        "main_dataframe.dropna(subset=['estado','municipio', 'codmun'], inplace=True)\n",
        "\n",
        "main_dataframe.set_index('data', inplace=True)\n",
        "main_dataframe.index = pd.to_datetime(main_dataframe.index)"
      ],
      "metadata": {
        "id": "vOPLRK6UTYzF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_to_concatenate = []\n",
        "for column in main_dataframe.columns[4:]:\n",
        "  grouped = main_dataframe.groupby('codmun').resample('1W')[column].sum()\n",
        "  data_to_concatenate.append(grouped.to_frame())\n",
        "\n",
        "res = pd.concat(data_to_concatenate, axis=1)\n",
        "\n",
        "res = res.reset_index(level=[0,1])\n",
        "res['Year'] = pd.DatetimeIndex(res['data']).year\n",
        "res['week'] = res['data'].dt.strftime(\"%U\")\n",
        "res['week'] = pd.to_numeric(res['week'])"
      ],
      "metadata": {
        "id": "lK6jDAa9YD3l"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Adding geographic distances"
      ],
      "metadata": {
        "id": "nhWaFFBCkPbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Important**: Sadly you can't mix the city codes from the IBGE dataset and those from SINAN's. The former have numberings with seven digits (while the latter has six) that do not overlap with latter.\n",
        "\n",
        "Proof:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "test = []\n",
        "\n",
        "for number in list(df_loc['MUN_ORIGEM'].unique()):\n",
        "  operationTwo = number\n",
        "  test.append( operationTwo // 10 )\n",
        "\n",
        "len(set(test) & set(df['cod_city'].unique())) #3710 vs 3774\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "UxJN1h6XkOdh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'your_path/'\n",
        "dbf = Dbf5(path + 'BR_Localidades_2010_v1.dbf', codec='latin')\n",
        "df_loc = dbf.to_dataframe()"
      ],
      "metadata": {
        "id": "vtjoViSBkOdh"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Dictionaty to convert full lenght UF names to codes\n",
        "#-> for some reason, the original dataframe, df, does not have data for Espirito Santo\n",
        "uf_code = ['RO', 'AC', 'AM', 'RR', 'PA', 'AP', 'TO', 'MA', 'PI', 'CE', 'RN',\n",
        "       'PB', 'PE', 'AL', 'SE', 'BA', 'MG', 'ES', 'RJ', 'SP', 'PR', 'SC', 'RS',\n",
        "       'MS', 'MT', 'GO', 'DF']\n",
        "uf_names = list(df_loc['NM_UF'].unique())\n",
        "\n",
        "for i in range(len(uf_code)):\n",
        "    df_loc['NM_UF'] = df_loc['NM_UF'].replace(uf_names[i],uf_code[i])"
      ],
      "metadata": {
        "id": "jjHHJzV7kOdh"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#-> Removing accents\n",
        "cols = df_loc.select_dtypes(include=[object]).columns\n",
        "df_loc[cols] = df_loc[cols].apply(lambda x: x.str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8'))"
      ],
      "metadata": {
        "id": "om0EDK__kOdh"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_loc = df_loc.loc[df_loc['NM_CATEGOR'] == 'CIDADE']\n",
        "df_loc['ID_MUNICIP'] = pd.to_numeric(df_loc['CD_GEOCODM'].str[:-1])\n",
        "\n",
        "df_loc.sort_values(by=['ID_MUNICIP'], inplace=True)"
      ],
      "metadata": {
        "id": "RFHoV1swkOdh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_coord = []\n",
        "y_coord = []\n",
        "city_to_remove = []\n",
        "\n",
        "for city in list(res['codmun'].unique()):\n",
        "  df_city = df_loc.loc[df_loc['ID_MUNICIP'] == city]\n",
        "  size_city_data = len(res.loc[res['codmun'] == city])\n",
        "  if (len(df_city) != 0):\n",
        "    x = df_city['LAT'].values[0]\n",
        "    y = df_city['LONG'].values[0]\n",
        "    x_coord.append( np.repeat(x, size_city_data) )\n",
        "    y_coord.append( np.repeat(y, size_city_data) )\n",
        "  else:\n",
        "    city_to_remove.append(city)\n",
        "\n",
        "x_coord = list(itertools.chain(*x_coord))\n",
        "y_coord = list(itertools.chain(*y_coord))"
      ],
      "metadata": {
        "id": "-Wlq-DmbkYvn"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for city in city_to_remove:\n",
        "  res = res[res['codmun'] != city]"
      ],
      "metadata": {
        "id": "JPG6iJRWuBp3"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Add the positions found in the previous cell\n",
        "res['x_coord'] = x_coord\n",
        "res['y_coord'] = y_coord"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "fc02ffb8-d278-4455-a51c-154d769fa340",
        "id": "2nymMl2ikm3y"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           codmun       data  casosAcumulado  casosNovos  Year  week  \\\n",
              "0        110001.0 2020-03-29             0.0           0  2020    13   \n",
              "1        110001.0 2020-04-05             0.0           0  2020    14   \n",
              "2        110001.0 2020-04-12             0.0           0  2020    15   \n",
              "3        110001.0 2020-04-19             0.0           0  2020    16   \n",
              "4        110001.0 2020-04-26             0.0           0  2020    17   \n",
              "...           ...        ...             ...         ...   ...   ...   \n",
              "1097285  530010.0 2023-12-03       6482474.0         258  2023    49   \n",
              "1097286  530010.0 2023-12-10       6484370.0         303  2023    50   \n",
              "1097287  530010.0 2023-12-17       6486391.0         253  2023    51   \n",
              "1097288  530010.0 2023-12-24       6487956.0         150  2023    52   \n",
              "1097289  530010.0 2023-12-31       6489230.0         262  2023    53   \n",
              "\n",
              "           x_coord    y_coord  \n",
              "0       -11.935540 -61.999824  \n",
              "1       -11.935540 -61.999824  \n",
              "2       -11.935540 -61.999824  \n",
              "3       -11.935540 -61.999824  \n",
              "4       -11.935540 -61.999824  \n",
              "...            ...        ...  \n",
              "1097285 -15.794087 -47.887905  \n",
              "1097286 -15.794087 -47.887905  \n",
              "1097287 -15.794087 -47.887905  \n",
              "1097288 -15.794087 -47.887905  \n",
              "1097289 -15.794087 -47.887905  \n",
              "\n",
              "[1096305 rows x 8 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>codmun</th>\n",
              "      <th>data</th>\n",
              "      <th>casosAcumulado</th>\n",
              "      <th>casosNovos</th>\n",
              "      <th>Year</th>\n",
              "      <th>week</th>\n",
              "      <th>x_coord</th>\n",
              "      <th>y_coord</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>110001.0</td>\n",
              "      <td>2020-03-29</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>13</td>\n",
              "      <td>-11.935540</td>\n",
              "      <td>-61.999824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>110001.0</td>\n",
              "      <td>2020-04-05</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>14</td>\n",
              "      <td>-11.935540</td>\n",
              "      <td>-61.999824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>110001.0</td>\n",
              "      <td>2020-04-12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>15</td>\n",
              "      <td>-11.935540</td>\n",
              "      <td>-61.999824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>110001.0</td>\n",
              "      <td>2020-04-19</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>16</td>\n",
              "      <td>-11.935540</td>\n",
              "      <td>-61.999824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>110001.0</td>\n",
              "      <td>2020-04-26</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2020</td>\n",
              "      <td>17</td>\n",
              "      <td>-11.935540</td>\n",
              "      <td>-61.999824</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097285</th>\n",
              "      <td>530010.0</td>\n",
              "      <td>2023-12-03</td>\n",
              "      <td>6482474.0</td>\n",
              "      <td>258</td>\n",
              "      <td>2023</td>\n",
              "      <td>49</td>\n",
              "      <td>-15.794087</td>\n",
              "      <td>-47.887905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097286</th>\n",
              "      <td>530010.0</td>\n",
              "      <td>2023-12-10</td>\n",
              "      <td>6484370.0</td>\n",
              "      <td>303</td>\n",
              "      <td>2023</td>\n",
              "      <td>50</td>\n",
              "      <td>-15.794087</td>\n",
              "      <td>-47.887905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097287</th>\n",
              "      <td>530010.0</td>\n",
              "      <td>2023-12-17</td>\n",
              "      <td>6486391.0</td>\n",
              "      <td>253</td>\n",
              "      <td>2023</td>\n",
              "      <td>51</td>\n",
              "      <td>-15.794087</td>\n",
              "      <td>-47.887905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097288</th>\n",
              "      <td>530010.0</td>\n",
              "      <td>2023-12-24</td>\n",
              "      <td>6487956.0</td>\n",
              "      <td>150</td>\n",
              "      <td>2023</td>\n",
              "      <td>52</td>\n",
              "      <td>-15.794087</td>\n",
              "      <td>-47.887905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1097289</th>\n",
              "      <td>530010.0</td>\n",
              "      <td>2023-12-31</td>\n",
              "      <td>6489230.0</td>\n",
              "      <td>262</td>\n",
              "      <td>2023</td>\n",
              "      <td>53</td>\n",
              "      <td>-15.794087</td>\n",
              "      <td>-47.887905</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1096305 rows × 8 columns</p>\n",
              "</div>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res.rename(columns={'codmun': 'cod_city', 'casosNovos': 'cases'}, inplace=True)\n",
        "res = res[['cod_city', 'Year', 'week', 'data', 'cases', 'x_coord', 'y_coord']]\n",
        "res['cases'].mask(res['cases'] <0 , 0, inplace=True)  #remove negative values. There seems to be a bug in the original data which needs to be fixed.\n",
        "\n",
        "res.to_csv(path + 'covid_2020_2023.csv')"
      ],
      "metadata": {
        "id": "JJ1N880JdC5s"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}